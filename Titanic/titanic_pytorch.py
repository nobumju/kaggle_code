# -*- coding: utf-8 -*-
"""titanic_pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oSgpl_KsuE8CQkeSUVqGtADAq0fAOIXV

전처리
"""

import numpy as np
import pandas as pd

dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DATA/train_titanic.csv')
X_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DATA/test_titanic.csv')

print(dataset.head(5))
dataset.describe()

dataset_title = [i.split(',')[1].split('.')[0].strip() for i in dataset['Name']]
dataset['Title'] = pd.Series(dataset_title)
dataset['Title'] = dataset['Title'].replace(['Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Ms', 'Mme', 'Mlle'], 'Rare')

dataset_title = [i.split(',')[1].split('.')[0].strip() for i in X_test['Name']]
X_test['Title'] = pd.Series(dataset_title)
X_test['Title'] = X_test['Title'].replace(['Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Ms', 'Mme', 'Mlle'], 'Rare')

dataset['FamilyS'] = dataset['SibSp'] + dataset['Parch'] + 1
X_test['FamilyS'] = X_test['SibSp'] + X_test['Parch'] + 1

def family(x):
    if x < 2:
        return 'Single'
    elif x == 2:
        return 'Couple'
    elif x <= 4:
        return 'InterM'
    else:
        return 'Large'

dataset['FamilyS'] = dataset['FamilyS'].apply(family)
X_test['FamilyS'] = X_test['FamilyS'].apply(family)

dataset["Age"] = dataset["Age"].fillna(dataset.groupby("Title")["Age"].transform("median"))
X_test["Age"] = X_test["Age"].fillna(X_test.groupby("Title")["Age"].transform("median"))

# 나머지 결측치 처리
dataset = dataset.fillna({
    'Embarked': dataset['Embarked'].mode()[0]
})
X_test = X_test.fillna({
    'Embarked': X_test['Embarked'].mode()[0],
    'Fare': X_test['Fare'].median()
})

dataset = dataset.drop(['PassengerId', 'Cabin', 'Name', 'SibSp', 'Parch', 'Ticket'], axis=1)
X_test_passengers = X_test['PassengerId']
X_test = X_test.drop(['PassengerId', 'Cabin', 'Name', 'SibSp', 'Parch', 'Ticket'], axis=1)

"""train"""

X_train = dataset.iloc[:, 1:9].values
Y_train = dataset.iloc[:, 0].values
X_test = X_test.values

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder_X_1 = LabelEncoder()
X_train[:, 1] = labelencoder_X_1.fit_transform(X_train[:, 1])
X_train[:, 4] = labelencoder_X_1.fit_transform(X_train[:, 4])
X_train[:, 5] = labelencoder_X_1.fit_transform(X_train[:, 5])
X_train[:, 6] = labelencoder_X_1.fit_transform(X_train[:, 6])

labelencoder_X_2 = LabelEncoder()
X_test[:, 1] = labelencoder_X_2.fit_transform(X_test[:, 1])
X_test[:, 4] = labelencoder_X_2.fit_transform(X_test[:, 4])
X_test[:, 5] = labelencoder_X_2.fit_transform(X_test[:, 5])
X_test[:, 6] = labelencoder_X_2.fit_transform(X_test[:, 6])

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
import numpy as np
import torch

ct = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), [1, 4, 5, 6]), # 범주형
        ('num', StandardScaler(), [0, 2, 3]) # 수치형 (여기서 이미 스케일링 완료)
    ],
    remainder='passthrough'
)

# 2. 딱 한 번만 변환 (여러 번 할 필요 없음)
# fit_transform은 학습 데이터에만!
X_train = ct.fit_transform(X_train)
# transform은 테스트 데이터에만! (학습 데이터의 기준을 따름)
X_test = ct.transform(X_test)

# 3. 행렬 형태 변환 (희소 행렬 방지)
if hasattr(X_train, "toarray"):
    X_train = X_train.toarray()
    X_test = X_test.toarray()

# 4. 타입 변환 및 텐서 생성
X_train = np.array(X_train, dtype=np.float32)
X_test = np.array(X_test, dtype=np.float32)

X_train_ts = torch.from_numpy(X_train)
X_test_ts = torch.from_numpy(X_test)

import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.model_selection import train_test_split

x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.001)
input_size = x_train.shape[1]

class Net(nn.Module):
    def __init__(self, input_size):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.bn1 = nn.BatchNorm1d(128) # 배치 정규화 추가
        self.fc2 = nn.Linear(128, 64)
        self.bn2 = nn.BatchNorm1d(64)
        self.fc3 = nn.Linear(64, 2)

    def forward(self, x):
        x = F.relu(self.bn1(self.fc1(x)))
        x = F.dropout(x, p=0.2)
        x = F.relu(self.bn2(self.fc2(x)))
        x = F.dropout(x, p=0.2)
        x = self.fc3(x) # Sigmoid 제거 (CrossEntropyLoss 사용 시)
        return x

net = Net(input_size)

batch_size = 64 # 배치 사이즈를 조금 줄여 학습 정교화
num_epochs = 200 # 학습 횟수 증가
learning_rate = 0.005 # 학습률 하향 조정

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-5) # L2 규제 추가

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)

import math
from sklearn.utils import shuffle
from torch.autograd import Variable
batch_no = math.ceil(len(x_train) / batch_size)
for epoch in range(num_epochs):
    if epoch % 5 == 0:
        print('Epoch {}'.format(epoch+1))

    # 1. Shuffle (numpy 배열일 때 가장 잘 작동)
    x_train, y_train = shuffle(x_train, y_train)

    # 2. Mini batch learning
    for i in range(batch_no):
        start = i * batch_size
        end = start + batch_size

        # 3. 최신 PyTorch 방식 (Variable 삭제, 명확한 텐서 변환)
        # x_train이 numpy 배열이라면 아래와 같이 변환
        x_var = torch.FloatTensor(x_train[start:end])
        y_var = torch.LongTensor(y_train[start:end])

        # Forward + Backward + Optimize
        optimizer.zero_grad()
        ypred_var = net(x_var)  # 여기서 이제 에러가 나지 않습니다!
        loss = criterion(ypred_var, y_var)
        loss.backward()
        optimizer.step()

"""test"""

test_var = Variable(torch.FloatTensor(x_val), requires_grad=True)
with torch.no_grad():
    result = net(test_var)
values, labels = torch.max(result, 1)
num_right = np.sum(labels.data.numpy() == y_val)
print('Accuracy {:.2f}'.format(num_right / len(y_val)))

net.eval()
X_test_var = Variable(torch.FloatTensor(X_test), requires_grad=True)
with torch.no_grad():
    test_result = net(X_test_var)
values, labels = torch.max(test_result, 1)
survived = labels.data.numpy()

import csv

submission = [['PassengerId', 'Survived']]
for i in range(len(survived)):
    submission.append([X_test_passengers[i], survived[i]])

with open('submission.csv', 'w') as submissionFile:
    writer = csv.writer(submissionFile)
    writer.writerows(submission)

print('Writing Complete!')